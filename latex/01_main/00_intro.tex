\chapter*[Introduction]{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\label{chap:intro}

\epigraph{
    ``The first and most fundamental rule is: Consider social facts as things.''
}{
    --- \textup{Emile Durkheim}, The Rules of Sociological Method
}
\nocite{durkheim1982}

\epigraph{
    ``You are gonna need a bigger boat''
}{
    --- \textup{Chief Brody}, Jaws
}

Sociology is the study of social facts.
Social facts are a tricky object of study, because they combine a material aspect with its symbolic interpretation, such that a proper understanding of social facts requires the consideration not only of the material facts that actualize them, but also their meaning.
The first rule of sociological method dictates that social facts should be treated \emph{as} things because they are \emph{not} things: they are things and their meaning.

This ontological feature of social facts imposes a problem for their epistemology, because the need to account for meaning in their proper understanding blurs the distinction between (the materiality of) data and (the manipulation of symbols in) theory.
This imposes a particular form of the identification problem:
In addition to the confusion between variations in an indicator and variations in the underlying phenomenon of interest presented by the classic identification problem, the study of social facts requires an additional distinction between variations in the material basis of social facts, their symbolic interpretation or both.\footnote{
    \label{foot:artefacts}
    Or neither, in the case of methodological artefacts. It must be noted that the version of the identification problem that I'm associating to the ontology of social facts is valid even in a situation of ``perfect indicators'' in the context of the traditional version of the identification problem
    % TODO citation needed.
}

This epistemological problem is more or less inescapable, as it is imposed by the ontology of social facts themselves.
But it is fundamentally practical (and an instance of an identification problem in a meaningful sense) to the extent that it is associated to the observational difficulties of studying meaning, which we normally access through interpretation.
It is the need for interpretation in order to access meaning that produces the blurring of data and theory that I am claiming to be constitutive\footnote{
    Or, in softer terms, ``a large source of''.
    The general argument still applies even if this point is conceded.
} of the epistemological problems associated to the study of social facts.
If there was an alternative way of accessing meaning, at least as data, that did not rely on interpretation such that the latter is restricted (or properly contained) to theoretical issues, some of the harder implications of the problem could be avoided.
This would also allow discussions about the relationship between meaning and social facts to move outside questions around the epistemological bases of the social sciences into properly theoretical questions about how to best account for data, as there would not be any confusion about meaning as object of study, captured as data and meaning as theory, produced by interpretation\footnote{
    \label{foot:interp1}
    This can't be emphasized enough:
    I may be arguing against some perils of interpretation in the production of sociological knowledge, but this critique is restricted exclusively to the role that interpretation plays \emph{in the production of data}.
    The perspective I am proposing in this dissertation does not \emph{prohibit} interpretation, it just restricts it.
    Or alternatively: it facilitates it as it protects it from the empirical questions that are relevant at the point of assessing the signals from data, releasing it from this problem in order to be freely applied in its proper place within a theoretic discussion.
}.

I think there is ample agreement about the generality of this problem, discussion around which has plagued the social sciences since it was first formulated as a \textit{Methodenstreit} in our discipline's origins in German economics\footnote{
    \label{foot:tarde}
    Its aftermath being, incidentally, the intellectual context in which Durkheim wrote his \emph{Rules of Sociological Method} and, to a large extent, the background for his controversy with Tarde, which revolved \emph{specifically} around the question about how the meanings associated to social facts by the actors that participate in them should be incorporated in their scientific understanding
    % TODO: add citation to the D/T debate as reproduced in the post-scriptum to the RSM.
}.
However, the general problem takes on different particular forms in its application in different sociological fields.
In the case of historical sociology, the problem takes on a more precise and more subtle form that nonetheless makes its problematic aspect more patent, as I will discuss below.
By historical sociology, I understand the study of social facts across time, which we can call social processes\footnote{
    \label{foot:histsoc}
    Sociology is the study of social facts.
    Social facts across time are social processes.
    The sum total of social facts is society, the sum total of social processes is history.
    The sociological study of history is historical sociology.
    The idea that what used to be called ``classical'' sociology has evolved into contemporary historical sociology is not new \citep{mahoney2003a}.
}.

\section*{The indeterminacy of the past}
\addcontentsline{toc}{section}{The indeterminacy of the past}
\label{sec:indeterminacy}

\citet{danto1985} argues that historical knowledge is constructed through narrative sentences, in which an event occurring at a given point in time is described by reference to other events that occur at points in time in the future of the event being described.
This implies that in the description of events in the past, we incorporate information that is generally not available at the point in time in which the events themselves occur\footnote{
    The canonical example is the proposition that says that ``the father of modern physics was born in 1643'', which can only be uttered after there was such a thing as modern physics that Isaac Newton could be the father of.
}.
This characteristic of narrative historical knowledge is known as the indeterminacy of the past:
The description of an event (i.e. the basis for any knowledge that can be produced about it) will change as new events occur and shed new light on the meaning of past events.

For Danto, the need for narrative knowledge to make sense of the past is justified because even if we had access to an ``ideal chronicle'' that recorded ``everything that happened as it happened'', \emph{making sense of it} would still require an exercise of imputation of the significance of different points in the chronicle, and this imputation can only proceed in the context of some narrative.
Events and narratives are then mutually constitutive: the former are only meaningful in the context of the latter, and the latter are nothing more than meaningful arrangements of the former.
% There is a nice connection here to the method proposed: carving out meaningful chunks from undifferentiated information, etc.

The connection between the indeterminacy of the past and the epistemological problem discussed above, is given by the fact that we never actually have access to an ideal chronicle, but only to prior narrative accounts.
In other words, narrativity characterizes not only the products of the historian's work, but also the results of the archivist's in their job of curating and selecting what is to be preserved about the past:
The sources that we have available as primary data in the production of narrative accounts are themselves narrative, to the extent that they are the result of a choice about their significance, and this choice is made in the context of the narratives that were available at the moment in which they were chosen to be preserved.
From here on out, it's turtles all the way down: narratives built upon narratives, interpretations of interpretations, such that one's historian's theories are a future historian's data.

Just as the general epistemological problem formulated above was profound to the extent that it is related to the ontology of social facts but still fundamentally practical in that it is related to the way in which we access meaning, the historical version of the problem (associated to the confusion between data and theory that we obtain when we deal with narrative accounts) is profound to the extent that it is associated to the fundamental characteristics of the kind of knowledge required to make sense of events in the past, but fundamentally practical, as this requirement is imposed by the choice of sequences of events as a model for history.

To state the argument in full:
The interpretation of history as an ordered sequence of discrete events forces us to use some form of narrative description in order to build historical knowledge.
The results of knowledge produced in this way will always be ad-hoc, because the basic entities that this knowledge will refer to are going to consist of events, and events can only be known by the part they play in a specific narrative.
Narratives can only be produced from the future, thus incorporating information that is not available at the moment in which the events themselves occur.
This issue affects not only the narratives that are produced by the historian (i.e. the theory that will be written by the sociologist) but also the narratives that are contained in the historical sources that will inform the historian's work (i.e. the accounts that are contained in the historical record).
And since narratives provide a mechanism to determine the significance of events within them, but no means to adjudicate between them, the only possible distinction that can be made between narrative data and narrative knowledge is based on the authority of the historian, which is to say: there is no valid distinction.

\section*{The inherent bias of eventful histories}
\addcontentsline{toc}{section}{The inherent bias of eventful histories}
\label{sec:bias}

The critique above could be accepted in full and discarded with a simple ``so what?''.
Let's accept that eventful histories provide no meaningful distinction between data and theory and that narrative accounts are non-unique, ad-hoc and decidable only on their usefulness (or the authority of their authors) and carry on without further complication; this is a viable position in the social sciences, that enjoys the added benefit of wasting no time in philosophico-epistemological disquisitions.

But there is an additional complication to the consideration of social processes (i.e. history) as ordered sequences of events: it introduces a pernicious form of bias that renders analyses blind to either continuity or change, and generally incapable of dealing with both at the same time.
This point merits a longer discussion.

One of the most enduring problems faced by the sociological analysis of large-scale processes of transformation is given by the intrinsic difficulty of the problem of choosing a suitable model of time.
In general, it is surprisingly unlikely that a chosen model will not bias our observations towards instances of either continuity or change.
More precisely, in most of the available theoretical frameworks in historical sociology, time is not only incorporated as a dimension of comparison (i.e. merely an ``independent variable''), but also as a defining feature of some theoretical entities.
In brief, the problem is that time-as-a-dimension is generally conceptualized in specific combinations as either continuity or change, producing theoretical frameworks that are capable of dealing with one or the other, but not both.

Most of the available theoretical frameworks in sociological analysis are either theories of continuity, or theories of change; change is not generally considered to be a contingent result of historical development, but to be constitutive of a series of discrete events. In most approaches, if there is no change, \emph{nothing happens}.

A good example of this problem is given by analyses of political processes.
If one reads the available literature on political historical sociology, one finds that there are broadly two major approaches\footnote{
    \label{foot:socmov}
    A third approach would be given by social movement studies, but work in this field is almost exclusively focused on mobilization, or the collective action problem faced by political movements with an explicit decision not to address the consequences of mobilization.% [TODO citation needed].
    If I were to extend my argument to incorporate social movement studies, then my criticism would revolve around the lack of a proper theoretical model for how institutions emerge out of processes of collective action, but this problem is, surprisingly, not within the scope of most social movements research.
} to the analysis of politics in this field:
Institutionalist approaches \citep{hall1996,thelen1999,thelen2003,mahoney2009,mahoney2010}, that focus on the explanation of the lack of change and are (correctly) criticized as being inherently static, and theories of revolution \citep{skocpol1979,goldstone1991,goldstone2001,sewell1985}, that only apply to situations of (rapid, profound) political transformations, and are thus restricted only to the consideration of ``complete'' revolutionary processes.
% TODO \footnote{
%    mention contrast with goldstone?
% }
There is no general theory of the political process that is applicable to both moments in political life and is thus capable of explaining (what one could argue to be) the more interesting problem of how the transition between the two operates; i.e. how it is that we move from a situation of continuity, maybe dominated by institutional, path-dependent dynamics, to a situation of rapid structural change which could be characterized as a revolution.

This is given by the fact that the two approaches incorporate a specific understanding of time and process in the definition of their principal theoretical entities:
For institutionalist approaches in the end ``institutions'' are equated with that which remains stable and constrain agency, and for revolutionary approaches, revolutions are defined as instances of rapid and profound structural change.
There is no space in either approach to conceptualize, for example, episodes of highly contentious non-institutional political struggle that, on the one hand, are not generally governed by institutional dynamics while at the same time do not produce any profound structural transformation\footnote{
    What happened in Zuccotti Park on September 17th, 2011?
}.

This limitation is not exclusive to political historical analysis and to some extent, the lack of integrated accounts of large-scale historical processes of transformation stems from this intrinsic limitation of the available theoretical frameworks, because large-scale processes of historical transformation are more than just uninteresting periods of continuity punctuated by events of structural change.

To avoid this problem, it becomes necessary to make a clean separation between temporality as a dimension of comparison (i.e. the mere temporal sorting of facts) and temporality as a defining feature of the relevant theoretical entities. E.g. institutions should not be defined as some residual category of that which does not change, because it is necessary to allow institutional permanence and institutional change to be theoretically available, contingent results of some observed historical process.

This implies rethinking what is normally understood by ``event'' in historical sociological analysis.
According to \citet{sewell1992,sewell1996}, events ``can be defined as that rare subclass of happenings that significantly transform structures. An eventful conception of temporality, therefore, is one that takes into account the transformation of structures by events'', which implies that in the absence of change, there are no events; nothing happens, and whatever does happen is considered to be a non-significant ``happening'' (sic).
From this point of view, history is an ordered sequence of discrete, significant changes and the only entities that can be properly defined are those that do participate in events and experience some form of ``structural'' change.
The rest are just residual non-significant elements.
In this sense, histories of events imply a particular form of selection bias, because events that ``fail'' to introduce ``structural'' change are not even considered to be events, and thus summarily eliminated from consideration.
This makes it impossible to speak of situations that fail to introduce change, or periods in which there is no appreciable change or whatever change there is is gradual and slow-moving, not associated to points of profound structural transformations.\footnote{
    See \cite{hagen2013,makovi2016} for a definitive demonstration of how the inclusion of ``failed'' events that would otherwise be summarily eliminated from the analysis produces a completely different explanation of an observed historical pattern.
}

\section*{Alternative representations of the past}
\addcontentsline{toc}{section}{Alternative representations of the past}
\label{sec:noevent}

The use of events as the fundamental unit of analysis for historical knowledge produces then an epistemological problem from the inevitable confusion between data and theory and a practical problem from its inherent bias towards instances of change and relative blindness to periods of uneventful continuity.

If it were possible to produce an alternative view of the past, that did not rely on events as their primary unit of analysis and consequently did not require an exercise of narrative interpretation in order to adjudicate their significance, these problems could be avoided.

In order to produce the kind of alternative representation of time that may provide a solution to the problems discussed above, we have to begin by recognizing that what we call events in narrative history are simply moments in time in which we observe some change in the state of affairs.
These changes may be qualified with additional adjectives, like in the definition proposed by Sewell that requires change to be ``structural'', but in any case they are a particular instance of a more general class of \emph{transitions} between \emph{states of affairs} that differ only in their locations in time.
If the preceding state of affairs is not similar to the succeeding state of affairs, we determine that we are in the presence of \emph{change}, and we identify that particular moment of transition as an event.

In general, we rely on narrative knowledge because in the production of the usual sources of information about the past, what has been preserved for us in the historical record is not a succession of pictures of states of affairs, but only those transitions between them that were perceived, at the time, to be instances of change.
This is what we call events and its ideal, exhaustive collection is what makes up \citeauthor{danto1985}'s ideal chronicle.
But if we were able to access some sort of ordered representation of the states of affairs at different points in time, irrespective of the similarity or dissimilarity between adjacent states of affairs, we could construct uneventful representations of the past, that would need no narrative account to adjudicate significance; it would be possible to measure it \emph{directly} from the difference between adjacent states of affairs.
This seems like a promising solution to the epistemological problem discussed above, as it would \emph{allow} for a narrative account if we were to focus our attention to those points of transition at which we observe greater differences between adjacent states of affairs to construct theoretical arguments, but it does not \emph{require} a narrative account to construct historical data.
It also seems like a promising solution to the practical problem of bias, as it would not exclude some transitions as a function of their participation in moments of change: ``Eventfulness'' would be a contingent result.

This dissertation is based on the idea that \emph{computational text analysis provides the means to produce the rich characterizations of successive states of affairs that are sufficient to sustain a non-eventful representation of the past}.
This exercise is possible because we now have at our disposal
    immense amounts of machine readable text from the historical record and
    a set of computational techniques that
    are capable of modeling the semantic content of these textual sources
    in a general way,
    not restricted to specific domains of knowledge or expertise,
    produced in a way in which they are particularly sensitive to small variations in the underlying sources of textual data,
    and generally not dependent on knowledge possessed by an analyst
    from the future.

In order for this approach to be viable, there are three requirements that must be satisfied:
First, we need to extend the scope of application of computational text analysis in sociological work beyond the study of discursive phenomena to which it has been mostly restricted so far.
Second, we need to fill in the lack of theoretical foundations of most of these techniques, both linguistically but above all sociologically, related to the specific relationship language has to social facts (beyond its strategic uses as discourse).
Finally, we need to provide a methodological framework within which to evaluate and combine the different techniques available for computational text analysis.
My concern at this point is primarily with the third issue; the other two are touched on to the extent they provide objectives and justifications to it.
The proposed methodological framework revolves around the solution to two practical problems: the identification of sociological facts in the pictures of states of affairs produced by computational text analysis, that I will refer to as the ``mapping'' problem, and the construction of measurements for similarity or dissimilarity between representations of pictures of different states of affairs that I will refer to as the ``alignment'' problem.

It seems necessary to emphasize a central idea behind this exercise: epistemological problems (and the practical ones that stem from their consequences) are basically problems that result not from the way things are, but from decisions we make about how to produce knowledge.
In the case of the problems discussed above, the specific choices that lie at their root have to do with the way in which we choose to represent time, the data structures these representations rely on and the analytical exercises that they necessitate.

In the specific case of historical knowledge and the problems associated to the role of narrative in its construction, this dissertation follows in the footsteps of a certain tradition within historical sociology that is based on this premise, however implicitly.
Work in this tradition is generally characterized by the same fundamental exercise proposed in this work, of using alternative data structures to represent a given source of historical data and using the analytical tools enabled by such representations to formulate new theoretical insights, but departs from it in that most of this work has generally revolved around the so-called ``casing problem''; the question about how to locate the boundaries of a given sequence of events in order to produce a case over which a narrative account can be sustained.
% TODO: citation needed
The approach presented here should be seen as a solution to a related problem: that of generating (or ``discovering'') meaningful sequences from undifferentiated data.
It is, in this sense, complementary to that approach as the results produced by the techniques discussed below could be used as the basis for the production of event sequences, but it pretends to have a more general application.

As argued above, I believe this exercise provides a solution to some deep problems in historical sociology and, if successful, opens up a whole new way of conducting social scientific research, to the extent that its application to historical sociological questions partly revolves around a reduced theoretical centrality of time as a defining feature of theoretical entities\footnote{
    \label{foot:time}
    A ``reduced theoretical centrality of time'' means that the approach discussed in this work may have applications to questions in \emph{general} sociology. See \autoref{sec:background}, and \autoref{chap:conc}.
}
But even if I fail in convincing of my giddy view of computational text analysis and the impact it may have on our discipline, skeptics may find value in this work to the extent that it offers a fundamentally practical overview of the many different techniques that are piled together as computational text analysis these days, in order to show how they all follow a more or less standard strategy of analysis, that can be parceled out into a series of independent modeling decisions, centered on the construction and projection of co-occurrence matrices.

I hope the practical emphasis of the discussion in the following pages will make these techniques available to a broader audience within the sociological field.
I don't think sharing my enthusiasm about their potential is necessary for them to be useful.

There are many buzzwords usually associated to the kind of work discussed in these pages, like artificial intelligence, deep learning, natural language processing, etc.
Marketing issues aside, the techniques discussed below all come down to the same exercise: counting words and then projecting the results of these counts into mathematical structures whose properties happen to approximate the way in which human languages encode meaning and context.
There is no magic here, these techniques are not the result of fundamental breakthroughs in our understanding of artificial intelligence or the linguistic machinery of natural human languages; the fundamental theoretical ideas that lie at the heart of the techniques discussed in this work were formulated in the nineteen fifties \citep{firth1957}, their methodological implications systematically explored in the nineteen nineties \citep{harris1988,harris1991}, and the techniques themselves have been developed empirically\footnote{
    \label{foot:empir1}
    ``Developed empirically'' means that we don't really have an explanation of why they work, just good results and performance metrics when they have been applied to concrete tasks.
    The fact that earlier semantic models were premised on ambitious claims of modeling human thought \citep{landauer1997,lund1996} and later models are not even properly understood by their authors \citep{mikolov2013,levy2014} is exemplary of this
}.
They are the inevitable result of having a bigger boat\footnote{
    \label{foot:boat}
    Write a computer program. Run it on some input. Now run it in parallel on thousands of CPUs on terabytes of input, and see what happens. This is basically the current state of the art in contemporary artificial intelligence and computational linguistics. It has shown to be \emph{extremely} effective.
}, and even though using them may require some familiarity with computer programming and understanding their inner workings may require some knowledge of graph theory or linear algebra, the logic behind most of them is rather straightforward once we look beyond the computational technicalities and intimidating topological theorems.
I expect the main value of this dissertation's contribution to lie in that exercise.

\section*{Layout of the work}
\addcontentsline{toc}{section}{Layout of the work}
\label{sec:layout}

The first chapter provides some theoretical background for the effort.
It first presents a critical review of the current state of the art in the application of computational text analysis to sociological problems, following the extremely thorough review recently compiled by \citet{evans2016}.
It then identifies the main limitations of current work in this field with their restriction to the study of discursive phenomena, and associates this limitation with a particular (and I argue insufficient) understanding of the social world as series of communicative ``games''. This is more or less in direct opposition to \citeauthor{evans2016}' proposed interpretation.
As an alternative, the chapter formulates a thin theoretical foundation for the application of text analysis to the study of non-discursive phenomena (which is what I refer to in this work's title by ``material'' processes).
This thin theory includes an exploration of the relationship between language and the social world that follows Searle's theory of the construction of social reality and Habermas' theory of communicative action, as well as an understanding of text as a \emph{sui-generis} material artefact developed as a technological solution to the problem of co-presence, an approach I like to think of as an ``archaeology of text''.
Since the main objective of this chapter is to satisfy the requirements imposed by the theoretical motivation discussed in this introduction, the first sections will be of little interest to the sceptical reader referred to above.
However, this chapter also formulates in excruciating detail the general methodological framework within which I am proposing to understand most computational text analysis for their application to sociological research, through a clear distinction of the different stages that these analyses need to go through, the problems that must be dealt with, the decisions they require from the researcher and the consequences they will have for the results.
The final section of the chapter offers a summarised version of my understanding of computational text analysis that should be sufficient to justify what I will attempt to show in the following chapters.

The second chapter introduces the Proceedings of the Old Bailey corpus, the primary data that will be used to demonstrate the techniques discussed in this dissertation.
In its presentation of the POB corpus, this chapter also discusses the general requirements that a time-ordered corpus needs to satisfy in order to be useful as a data source for the construction of non-narrative pictures of states of affairs.
This is fundamentally associated to the short ``narrative horizon'' of bureaucratic texts, and motivates a brief digression on the status of criminal trial proceedings as an historical source.
In brief, this section explains why sources like judicial transcripts and other legal or bureaucratic texts are more interesting than speeches, diaries, letters or newspapers, even for analyses that are not interested in legal or administrative phenomena.
Finally, it produces a general characterisation of the 240 year period covered by the POB corpus from the data contained in it and demonstrates how simple lexical analyses can be used to determine the outlines of historical processes both longitudinally and cross-sectionally with respect to the time dimension.
This is mostly related to an exercise of comparison between relative term frequency distributions across different time points and across different corpus regions, which motivates a discussion of document sampling.
% TODO
% Special attention is given to two processes of interest, the analysis of which will serve as a reference point for the discussion in the following chapters: gender relations and interpersonal violence.

The third chapter deals with semantic networks, the many options available for their construction and analysis and the requirements that must be satisfied in order to apply these rich data structures to the study of non-discursive problems.
These are fundamentally related to moving the focus of attention beyond questions of topicality for which I propose moving the semantic target from syntagmatic to paradigmatic relations between words.
This is first demonstrated by presenting and contrasting different semantic-network representations of the same object: the trial of Arthur Crouch, a case of domestic violence in the winter of 1894.
This comparison allows me to show how a particular social interaction can be characterised by the general strategy behind all semantic network approaches: pairwise distances between words induced by different measures of semantic similarity.
It also illustrates how the produced networks differ as we change the measures of similarity used to build them, specifically those that capture syntagmatic and paradigmatic similarities.
The same technique is then scaled up to analyse the entire POB corpus in order to illustrate how the social processes detected via the lexical analysis presented in the first chapter look like ``from the inside'' and to illustrate how the mapping and alignment problems are solved when the information contained in the co-occurrence matrix is projected into graph (network) structures.

The fourth chapter discusses semantic vector spaces and the general ideas behind their construction and manipulation.
Vector spaces overcome many of the limitations of semantic networks because they do not rely on computationally intensive graph-theoretical operations but on much simpler (and some would argue, more elegant) linear algebraic operations.
The study of meaning through linear algebraic operations in vector spaces is possible because semantic vector spaces encode semantic relationships between words in linear relationships between points in a high dimensional vector space, instead of the more complex encoding of the same information through structural features in graphs as is the case in semantic networks.
From a practical point of view, these features of semantic vector spaces allow them to cope with the entirety of the semantic space, eliminating the problems derived from the lexical sampling that is necessary in order to make semantic networks manageable.
In addition, and because of the same reasons, vector spaces are more suitable for the study of questions that do not map easily to the ``groups of words'' that are used to solve the mapping problem in network structures, because they allow for an alternative strategy based on the tracing of semantically relevant dimensions that organise and partition the vector space and that allow mapping many phenomena of interest in the social sciences (like any dimension of differentiation).
This also requires a different strategy for dealing with the alignment problem, based on the generation of compatible basis sets for
different vector space representations, through the generalised solution to the Procrustes problem.

Finally, the fifth chapter presents a recapitulation of the general methodological principles proposed for the application of computational text analysis to historical sociology, as well as discussing the general outlines of a broad research program centred on the construction and maintenance of ``online''\footnote{
    \label{foot:online}
    ``Online'' here refers to the fact that the values of the vector space are updated dynamically as new observations are incorporated, per opposition to one-off solutions that compute vector spaces statically from a fixed set of observations.
} semantic spaces for different historical cases.
This motivates a discussion of the different strategies that are available for the computation of word embedding, the dense vectors that make up a semantic space, and discusses the differences between online and offline algorithms.
Two alternatives are presented as promising avenues for future research: Sahlgren's random indexing and Gentleman's algorithm.
